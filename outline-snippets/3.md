# Motivation
- Deep Neural Nets are highly suitable for counterfactual inference
- But we have to deal with different distributions / covariate shift
- We need also need to regularise them
- It would be desirable to have a mesaure of certainty

# Model Description
- Show graph
- Use Multi-task learning
    + What are the benefits? 
- Use Propensity Dropout
    + What are the benefits? 
- 

# Multi-Task Learning
- Describe Architecture
-  

# Propensity-Based Dropout
- See paper
- How do we learn the propensity score? 
- Show formula
- Why does it make sense
- Confidence!

# Training the Model
- Alternate Training
- Show Algorithm 
- Explain Algorithm
- Explain Hyper-parameters

