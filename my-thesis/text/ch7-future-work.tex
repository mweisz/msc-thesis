%\begin{savequote}[8cm]
%\textlatin{Jedem Anfang wohnt ein Zauber innne.}
%
%In the core of every beginning lives magic.
%  \qauthor{--- Hermann Hesse's \textit{Stufen}}
%\end{savequote}

\chapter{\label{ch:7-future-work}Future Work} 
In the previous chapter we have discussed the findings of the project, the contributions of our models, and their potential limitations. Consequently, we provide a list of open research questions that can be considered the subject of future work in the field of counterfactual inference. 

\paragraph{Multiple Treatments} In order to address more complex real-world problems, it would be of great interest to investigate how our models can be generalised towards a multi-variate setting in which we are dealing with multiple feature assignments simultaneously. The multi-task learning framework that we are using for DCNs should in theory be able to accommodate non-binary setting with more than two separate but related tasks. However, additional challenges such as the interdependence and joint effects of the treatments have to be taken into account as well posing a variety of open research questions. 

\paragraph{Time-Series Data} It would be of great relevance to investigate how our models can be extended to time-series input data that contains temporal dependencies between the features. Future work in this field might examine the effectiveness of a multi-task framework with propensity-dropout to a recurrent neural network. 

\paragraph{Extensions of Propensity-Dropout} While our proposed propensity-based dropout scheme provides promising first results in the experiments, it would be interesting to investigate how the propensity score could also be used in competing regularising approaches such as DropConnect. % CITE Dropconnect

\paragraph{Empirical Model for Architecture Learning} Our approach of automatically inferring an appropriated DCN architecture is based on an empirical model that is trained in a supervised setting on synthetically-generated datasets. Due to the very nature of such a heuristic approach, the empirical model should be subject to ongoing research and improvements. In particular, it could be beneficial to analyse how we can ensure that the synthetically-generated have similar properties to real-world datasets in order to allow a maximum level of generalisation.  

git 


%## DCN-PD:
%- Multiple treatments?
%- Time series data? 
%- Can we adapt our multi-class learning to an RNN? 
%- Propensity-based DropConnect?
%
%## DCN-LA:
%- Run data on other datasets
%- Improve empirical model (more training data, other heuristics to infer the charactistics, etc.)
%- More experiments, 
%- Other features? 


%\minitoc

