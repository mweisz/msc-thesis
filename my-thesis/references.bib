
@inproceedings{multi-task-learning,
	author = {Collobert, Ronan and Weston, Jason},
	title = {A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning},
	booktitle = {Proceedings of the 25th International Conference on Machine Learning},
	series = {ICML '08},
	year = {2008},
	isbn = {978-1-60558-205-4},
	location = {Helsinki, Finland},
	pages = {160--167},
	numpages = {8},
	url = {http://doi.acm.org/10.1145/1390156.1390177},
	doi = {10.1145/1390156.1390177},
	acmid = {1390177},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@article{dropout,
	author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
	title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
	journal = {Journal of Machine Learning Research},
	year    = {2014},
	volume  = {15},
	pages   = {1929-1958},
	url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@article{propensity-score,
	author = {Rosenbaum, Paul R. and Rubin, Donald B.},
	title = {The central role of the propensity score in observational studies for causal effects},
	journal = {Biometrika},
	volume = {70},
	number = {1},
	pages = {41-55},
	year = {1983},
	doi = {10.1093/biomet/70.1.41},
	URL = { + http://dx.doi.org/10.1093/biomet/70.1.41},
	eprint = {/oup/backfile/content_public/journal/biomet/70/1/10.1093/biomet/70.1.41/2/70-1-41.pdf}
}

@book{ml-definition,
	author = {Mitchell, Thomas M.},
	title = {Machine Learning},
	year = {1997},
	isbn = {0070428077, 9780070428072},
	edition = {1},
	publisher = {McGraw-Hill, Inc.},
	address = {New York, NY, USA},
	pages = {2}
} 


@book{reinforcement-learning,
	author = {Sutton, Richard S. and Barto, Andrew G.},
	title = {Introduction to Reinforcement Learning},
	year = {1998},
	isbn = {0262193981},
	edition = {1st},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
} 

@book{number-of-neurons,
	title={What Makes Us Think?: A Neuroscientist and a Philosopher Argue about Ethics, Human Nature, and the Brain},
	author={Changeux, J.P. and Ricoeur, P. and DeBevoise, M.B.},
	isbn={9780691092850},
	lccn={00024827},
	url={https://books.google.co.uk/books?id=yDoT3rUYWjAC},
	year={2002},
	publisher={Princeton University Press}
}


@Article{nn-history,
	author="McCulloch, Warren S.
	and Pitts, Walter",
	title="A logical calculus of the ideas immanent in nervous activity",
	journal="The bulletin of mathematical biophysics",
	year="1943",
	month="Dec",
	day="01",
	volume="5",
	number="4",
	pages="115--133",
	abstract="Because of the ``all-or-none'' character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.",
	issn="1522-9602",
	doi="10.1007/BF02478259",
	url="https://doi.org/10.1007/BF02478259"
}

@incollection{imagenet,
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = {Advances in Neural Information Processing Systems 25},
	editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
	pages = {1097--1105},
	year = {2012},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}


@article{backprop1, 
	author={S. Dreyfus}, 
	journal={IEEE Transactions on Automatic Control}, 
	title={The computational solution of optimal control problems with time lag}, 
	year={1973}, 
	volume={18}, 
	number={4}, 
	pages={383-385}, 
	doi={10.1109/TAC.1973.1100330}, 
	ISSN={0018-9286}, 
	month={Aug},
}


@article{nlp,
	author    = {Nal Kalchbrenner and
	Edward Grefenstette and
	Phil Blunsom},
	title     = {A Convolutional Neural Network for Modelling Sentences},
	journal   = {CoRR},
	volume    = {abs/1404.2188},
	year      = {2014},
	url       = {http://arxiv.org/abs/1404.2188},
	timestamp = {Wed, 07 Jun 2017 14:42:24 +0200},
	biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/KalchbrennerGB14},
	bibsource = {dblp computer science bibliography, http://dblp.org}
}

@online{alphago,
	ALTauthor = {BBC},
	ALTeditor = {editor},
	title = {Artificial intelligence: Google's AlphaGo beats Go master Lee Se-dol},
	date = {2016-03-12},
	url = {http://www.bbc.co.uk/news/technology-35785875},

}


@Article{mlp-power,
	author="Cybenko, G.",
	title="Approximation by superpositions of a sigmoidal function",
	journal="Mathematics of Control, Signals and Systems",
	year="1989",
	month="Dec",
	day="01",
	volume="2",
	number="4",
	pages="303--314",
	abstract="In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.",
	issn="1435-568X",
	doi="10.1007/BF02551274",
	url="https://doi.org/10.1007/BF02551274"
}




