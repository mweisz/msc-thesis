
@inproceedings{multi-task-learning,
	author = {Collobert, Ronan and Weston, Jason},
	title = {A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning},
	booktitle = {Proceedings of the 25th International Conference on Machine Learning},
	series = {ICML '08},
	year = {2008},
	isbn = {978-1-60558-205-4},
	location = {Helsinki, Finland},
	pages = {160--167},
	numpages = {8},
	url = {http://doi.acm.org/10.1145/1390156.1390177},
	doi = {10.1145/1390156.1390177},
	acmid = {1390177},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@article{dropout,
	author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
	title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
	journal = {Journal of Machine Learning Research},
	year    = {2014},
	volume  = {15},
	pages   = {1929-1958},
	url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@article{propensity-score,
	author = {Rosenbaum, Paul R. and Rubin, Donald B.},
	title = {The central role of the propensity score in observational studies for causal effects},
	journal = {Biometrika},
	volume = {70},
	number = {1},
	pages = {41-55},
	year = {1983},
	doi = {10.1093/biomet/70.1.41},
	URL = { + http://dx.doi.org/10.1093/biomet/70.1.41},
}

@book{ml-definition,
	author = {Mitchell, Thomas M.},
	title = {Machine Learning},
	year = {1997},
	isbn = {0070428077, 9780070428072},
	edition = {1},
	publisher = {McGraw-Hill, Inc.},
	address = {New York, NY, USA},
	pages = {2}
} 


@book{reinforcement-learning,
	author = {Sutton, Richard S. and Barto, Andrew G.},
	title = {Introduction to Reinforcement Learning},
	year = {1998},
	isbn = {0262193981},
	edition = {1st},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
} 

@book{number-of-neurons,
	title={What Makes Us Think?: A Neuroscientist and a Philosopher Argue about Ethics, Human Nature, and the Brain},
	author={Changeux, J.P. and Ricoeur, P. and DeBevoise, M.B.},
	isbn={9780691092850},
	lccn={00024827},
	url={https://books.google.co.uk/books?id=yDoT3rUYWjAC},
	year={2002},
	publisher={Princeton University Press}
}


@Article{nn-history,
	author="McCulloch, Warren S.
	and Pitts, Walter",
	title="A logical calculus of the ideas immanent in nervous activity",
	journal="The bulletin of mathematical biophysics",
	year="1943",
	month="Dec",
	day="01",
	volume="5",
	number="4",
	pages="115--133",
	abstract="Because of the ``all-or-none'' character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.",
	issn="1522-9602",
	doi="10.1007/BF02478259",
	url="https://doi.org/10.1007/BF02478259"
}

@incollection{imagenet,
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = {Advances in Neural Information Processing Systems 25},
	editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
	pages = {1097--1105},
	year = {2012},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}


@article{backprop1, 
	author={S. Dreyfus}, 
	journal={IEEE Transactions on Automatic Control}, 
	title={The computational solution of optimal control problems with time lag}, 
	year={1973}, 
	volume={18}, 
	number={4}, 
	pages={383-385}, 
	doi={10.1109/TAC.1973.1100330}, 
	ISSN={0018-9286}, 
	month={Aug},
}


@article{nlp,
	author    = {Nal Kalchbrenner and
	Edward Grefenstette and
	Phil Blunsom},
	title     = {A Convolutional Neural Network for Modelling Sentences},
	journal   = {CoRR},
	volume    = {abs/1404.2188},
	year      = {2014},
	url       = {http://arxiv.org/abs/1404.2188},
	timestamp = {Wed, 07 Jun 2017 14:42:24 +0200},
	biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/KalchbrennerGB14},
	bibsource = {dblp computer science bibliography, http://dblp.org}
}

@online{alphago,
	ALTauthor = {BBC},
	ALTeditor = {editor},
	title = {Artificial intelligence: Google's AlphaGo beats Go master Lee Se-dol},
	date = {2016-03-12},
	url = {http://www.bbc.co.uk/news/technology-35785875},

}


@Article{mlp-power,
	author="Cybenko, G.",
	title="Approximation by superpositions of a sigmoidal function",
	journal="Mathematics of Control, Signals and Systems",
	year="1989",
	month="Dec",
	day="01",
	volume="2",
	number="4",
	pages="303--314",
	abstract="In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.",
	issn="1435-568X",
	doi="10.1007/BF02551274",
	url="https://doi.org/10.1007/BF02551274"
}


@INPROCEEDINGS{inductive-bias,
	author = {Richard Caruana},
	title = {Multitask Learning: A Knowledge-Based Source of Inductive Bias},
	booktitle = {Proceedings of the Tenth International Conference on Machine Learning},
	year = {1993},
	pages = {41--48},
	publisher = {Morgan Kaufmann}
}

@inproceedings{bayesian-optimisation,
	author = {Mockus, Jonas},
	title = {On Bayesian Methods for Seeking the Extremum},
	booktitle = {Proceedings of the IFIP Technical Conference},
	year = {1974},
	isbn = {3-540-07165-2},
	pages = {400--404},
	numpages = {5},
	url = {http://dl.acm.org/citation.cfm?id=646296.687872},
	acmid = {687872},
	publisher = {Springer-Verlag},
	address = {London, UK, UK},
} 

@incollection{bayesian-optimisation-results,
	title = {Practical Bayesian Optimization of Machine Learning Algorithms},
	author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
	booktitle = {Advances in Neural Information Processing Systems 25},
	editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
	pages = {2951--2959},
	year = {2012},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf}
}


@article{potential-outcomes,
	author = {Donald B Rubin},
	title = {Causal Inference Using Potential Outcomes},
	journal = {Journal of the American Statistical Association},
	volume = {100},
	number = {469},
	pages = {322-331},
	year = {2005},
	doi = {10.1198/016214504000001880},
	
	URL = { 
	http://dx.doi.org/10.1198/016214504000001880
	
	}
	
}

@article{domain-adaptation,
	author    = {Hal Daum{\'{e}} III and
	Daniel Marcu},
	title     = {Domain Adaptation for Statistical Classifiers},
	journal   = {CoRR},
	volume    = {abs/1109.6341},
	year      = {2011},
	url       = {http://arxiv.org/abs/1109.6341},
	timestamp = {Wed, 07 Jun 2017 14:41:07 +0200},
	biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1109-6341},
	bibsource = {dblp computer science bibliography, http://dblp.org}
}


@workingpaper {propensity-score-matching-sucks,
	title = {Why Propensity Scores Should Not Be Used for Matching},
	year = {Working Paper},
	abstract = {We show that propensity score matching (PSM), an enormously popular method of preprocessing data for causal inference, often accomplishes the opposite of its intended goal -- increasing imbalance, inefficiency, model dependence, and bias. PSM supposedly makes it easier to find matches by projecting a large number of covariates to a scalar propensity score and applying a single model to produce an unbiased estimate. However, in observational analysis the data generation process is rarely known and so users typically try many models before choosing one to present. The weakness of PSM comes from its attempts to approximate a completely randomized experiment, rather than, as with other matching methods, a more efficient fully blocked randomized experiment. PSM is thus uniquely blind to the often large portion of imbalance that can be eliminated by approximating full blocking with other matching methods. Moreover, in data balanced enough to approximate complete randomization, either to begin with or after pruning some observations, PSM approximates random matching which, we show, increases imbalance even relative to the original data. Although these results suggest that researchers replace PSM with one of the other available methods when performing matching, propensity scores have many other productive uses.},
	author = {Gary King and Richard Nielsen}
}


@ARTICLE{random-forests,
	author = {{Wager}, S. and {Athey}, S.},
	title = "{Estimation and Inference of Heterogeneous Treatment Effects using Random Forests}",
	journal = {ArXiv e-prints},
	archivePrefix = "arXiv",
	eprint = {1510.04342},
	primaryClass = "stat.ME",
	keywords = {Statistics - Methodology, Mathematics - Statistics Theory, Statistics - Machine Learning},
	year = 2015,
	month = oct,
	adsurl = {http://adsabs.harvard.edu/abs/2015arXiv151004342W},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{sontag-direct-modelling,
	author = {{Shalit}, U. and {Johansson}, F.~D. and {Sontag}, D.},
	title = "{Estimating individual treatment effect: generalization bounds and algorithms}",
	journal = {ArXiv e-prints},
	archivePrefix = "arXiv",
	eprint = {1606.03976},
	primaryClass = "stat.ML",
	keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Learning},
	year = 2016,
	month = jun,
	adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160603976S},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{sontag-paper,
	author = {{Johansson}, F.~D. and {Shalit}, U. and {Sontag}, D.},
	title = "{Learning Representations for Counterfactual Inference}",
	journal = {ArXiv e-prints},
	archivePrefix = "arXiv",
	eprint = {1605.03661},
	primaryClass = "stat.ML",
	keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Learning},
	year = 2016,
	month = may,
	adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160503661J},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{virtual-twin,
	author = {{Lu}, M. and {Sadiq}, S. and {Feaster}, D.~J. and {Ishwaran}, H.
	},
	title = "{Estimating Individual Treatment Effect in Observational Data Using Random Forest Methods}",
	journal = {ArXiv e-prints},
	archivePrefix = "arXiv",
	eprint = {1701.05306},
	primaryClass = "stat.ML",
	keywords = {Statistics - Machine Learning},
	year = 2017,
	month = jan,
	adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170105306L},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{dropout-confidence,
	author = {{Gal}, Y. and {Ghahramani}, Z.},
	title = "{Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning}",
	journal = {ArXiv e-prints},
	archivePrefix = "arXiv",
	eprint = {1506.02142},
	primaryClass = "stat.ML",
	keywords = {Statistics - Machine Learning, Computer Science - Learning},
	year = 2015,
	month = jun,
	adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150602142G},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{adam,
	author    = {Diederik P. Kingma and
	Jimmy Ba},
	title     = {Adam: {A} Method for Stochastic Optimization},
	journal   = {CoRR},
	volume    = {abs/1412.6980},
	year      = {2014},
	url       = {http://arxiv.org/abs/1412.6980},
	timestamp = {Wed, 07 Jun 2017 14:40:52 +0200},
	biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/KingmaB14},
	bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{hill,
	author = {Jennifer L. Hill},
	title = {Bayesian Nonparametric Modeling for Causal Inference},
	journal = {Journal of Computational and Graphical Statistics},
	volume = {20},
	number = {1},
	pages = {217-240},
	year = {2011},
	doi = {10.1198/jcgs.2010.08162},
	
	URL = { 
	http://dx.doi.org/10.1198/jcgs.2010.08162
	},
}

@ARTICLE{chipman,
	author = {{Chipman}, H.~A. and {George}, E.~I. and {McCulloch}, R.~E.},
	title = "{BART: Bayesian additive regression trees}",
	journal = {ArXiv e-prints},
	archivePrefix = "arXiv",
	eprint = {0806.3286},
	primaryClass = "stat.ME",
	keywords = {Statistics - Methodology, Statistics - Applications, Statistics - Machine Learning},
	year = 2008,
	month = jun,
	adsurl = {http://adsabs.harvard.edu/abs/2008arXiv0806.3286C},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{unos,
	author = {J.M. Cecka },
	title = "{The UNOS Scientific Renal Transplant Registry}",
	journal = {Clinical transplants 114},
	year = 1996,
}

